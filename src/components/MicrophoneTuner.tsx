// // –≠—Ñ—Ñ–µ–∫—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è isListening
// useEffect(() => {
//   console.log("–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è –Ω–∞:", isListening);
  
//   if (isListening) {
//     console.log("–ó–∞–ø—É—Å–∫ analyzeAudio –∏–∑ useEffect");
//     window.setTimeout(() => {
//       analyzeAudio();
//     }, 100);
//   } else {
//     console.log("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–Ω–∞–ª–∏–∑–∞");
//     if (rafIdRef.current) {
//       cancelAnimationFrame(rafIdRef.current);
//       rafIdRef.current = null;
//     }
//   }
// }, [isListening]);
// 
"use client";

import React, { useState, useEffect, useRef } from 'react';
import { 
identifyNote, 
calculateRMS
} from '@/utils/audioUtils';
import { NOTE_FREQUENCIES, NOTE_NAMES_RU } from '@/constants/noteFrequencies';
import { yinPitchTracking } from '@/utils/pitchTracking';

/**
* MicrophoneTuner component - A real-time musical instrument tuner using microphone input
*/
const MicrophoneTuner: React.FC = () => {
// State for microphone and analysis
const [isListening, setIsListening] = useState<boolean>(false);
const [hasMicrophonePermission, setHasMicrophonePermission] = useState<boolean | null>(null);
const [error, setError] = useState<string>('');
const [volume, setVolume] = useState<number>(0);
const [detectedNote, setDetectedNote] = useState<{
  note: string;
  nameRu: string;
  frequency: number;
  cents: number;
} | null>(null);
const [referenceFrequency, setReferenceFrequency] = useState<number>(440); // A4 = 440Hz standard

// Refs for Web Audio API objects
const audioContextRef = useRef<AudioContext | null>(null);
const analyserNodeRef = useRef<AnalyserNode | null>(null);
const microphoneStreamRef = useRef<MediaStream | null>(null);
const sourceNodeRef = useRef<MediaStreamAudioSourceNode | null>(null);
const rafIdRef = useRef<number | null>(null);

// Ref for audio buffer for pitch analysis
const audioBufferRef = useRef<AudioBuffer | null>(null);

// Refs for timing and note stability
const lastNoteRef = useRef<string | null>(null);
const noteStabilityCounterRef = useRef<number>(0);
const lastAnalysisTimeRef = useRef<number>(0);

// Constants
const ANALYSIS_INTERVAL = 100; // ms between analyses
const NOTE_STABILITY_THRESHOLD = 3; // how many consecutive same notes to consider it stable
const VOLUME_THRESHOLD = 0.01; // minimum volume to consider for analysis

/**
 * Initializes the audio context and analyzer node
 */
const initializeAudio = async (): Promise<boolean> => {
  try {
    console.log("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ...");
    
    // –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å—Ç–∞—Ä—ã–π –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
    if (audioContextRef.current) {
      try {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–∫—Ä—ã—Ç –ª–∏ —É–∂–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if (audioContextRef.current.state !== 'closed') {
          audioContextRef.current.close();
        }
        audioContextRef.current = null;
      } catch (closeErr) {
        console.warn("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ —Å—Ç–∞—Ä–æ–≥–æ AudioContext:", closeErr);
        // –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ –∑–∞–∫—Ä—ã—Ç–∏—è
      }
    }
    
    // Check if browser supports Web Audio API
    if (typeof window === 'undefined') {
      throw new Error('–ë—Ä–∞—É–∑–µ—Ä–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ');
    }
    
    if (!window.AudioContext && !window.webkitAudioContext) {
      throw new Error('Web Audio API –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ –≤–∞—à–µ–º –±—Ä–∞—É–∑–µ—Ä–µ');
    }
    
    // Check if MediaDevices API is available
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      throw new Error('API –¥–æ—Å—Ç—É–ø–∞ –∫ –º–µ–¥–∏–∞-—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ –≤–∞—à–µ–º –±—Ä–∞—É–∑–µ—Ä–µ');
    }
    
    // –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    const AudioContextClass = window.AudioContext || window.webkitAudioContext;
    const audioContext = new AudioContextClass();
    audioContextRef.current = audioContext;
    
    console.log("AudioContext —Å–æ–∑–¥–∞–Ω:", audioContext.state);
    
    // Create analyzer node
    const analyserNode = audioContext.createAnalyser();
    analyserNode.fftSize = 2048; // Large FFT for better frequency resolution
    analyserNode.smoothingTimeConstant = 0.8; // Smoothing to reduce jitter
    analyserNodeRef.current = analyserNode;
    
    console.log("–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É...");
    setError("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É...");
    
    // Request microphone access
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });
      
      if (!stream) {
        throw new Error('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞');
      }
      
      console.log("–î–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –ø–æ–ª—É—á–µ–Ω. –¢—Ä—ç–∫–∏:", stream.getAudioTracks().length);
      
      // –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ø–æ—Ç–æ–∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
      if (microphoneStreamRef.current) {
        microphoneStreamRef.current.getTracks().forEach(track => track.stop());
      }
      
      microphoneStreamRef.current = stream;
      
      // –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π source node, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
      if (sourceNodeRef.current) {
        sourceNodeRef.current.disconnect();
      }
      
      // Create source node from microphone input
      const sourceNode = audioContext.createMediaStreamSource(stream);
      sourceNodeRef.current = sourceNode;
      
      // Connect the source to the analyzer
      sourceNode.connect(analyserNode);
      
      // Create an offline buffer for pitch analysis
      const bufferSize = audioContext.sampleRate * 0.5; // 500ms buffer
      audioBufferRef.current = audioContext.createBuffer(
        1, bufferSize, audioContext.sampleRate
      );
      
      setHasMicrophonePermission(true);
      setError('');
      
      return true;
    } catch (micError) {
      console.error('–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É:', micError);
      setHasMicrophonePermission(false);
      setError(`–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É: ${micError instanceof Error ? micError.message : '–û—Ç–∫–∞–∑ –≤ –¥–æ—Å—Ç—É–ø–µ'}`);
      
      // –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
      if (audioContextRef.current) {
        try {
          audioContextRef.current.close();
          audioContextRef.current = null;
        } catch (e) {
          console.warn("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ AudioContext –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏ –¥–æ—Å—Ç—É–ø–∞:", e);
        }
      }
      
      return false;
    }
  } catch (err) {
    console.error('–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞—É–¥–∏–æ:', err);
    setHasMicrophonePermission(false);
    setError(`–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: ${err instanceof Error ? err.message : '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'}`);
    return false;
  }
};

/**
 * Starts listening to the microphone
 */
const startListening = async (): Promise<void> => {
  setError('–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...');
  console.log('–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞');
  
  // –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∑–∞–ø—É—Å–∫–µ,
  // —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å –∑–∞–∫—Ä—ã—Ç—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
  const success = await initializeAudio();
  
  if (success) {
    console.log('–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞, –Ω–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑');
    setIsListening(true);
    // –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑
    window.setTimeout(() => {
      analyzeAudio();
    }, 100);
  } else {
    console.log('–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å');
    setError('–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –±—Ä–∞—É–∑–µ—Ä–∞.');
  }
};

/**
 * Stops listening to the microphone
 */
const stopListening = (): void => {
  console.log('–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞');
  setIsListening(false);
  
  // Cancel any pending animation frame
  if (rafIdRef.current) {
    console.log('–û—Ç–º–µ–Ω–∞ –∞–Ω–∏–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ñ—Ä–µ–π–º–∞:', rafIdRef.current);
    cancelAnimationFrame(rafIdRef.current);
    rafIdRef.current = null;
  }
  
  // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
  if (microphoneStreamRef.current) {
    console.log('–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ç–æ–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞');
    microphoneStreamRef.current.getTracks().forEach(track => track.stop());
    microphoneStreamRef.current = null;
  }
  
  // –ù–ï –∑–∞–∫—Ä—ã–≤–∞–µ–º AudioContext, –∞ —Ç–æ–ª—å–∫–æ –æ—Ç–∫–ª—é—á–∞–µ–º —É–∑–ª—ã
  if (sourceNodeRef.current) {
    console.log('–û—Ç–∫–ª—é—á–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∑–≤—É–∫–∞');
    try {
      sourceNodeRef.current.disconnect();
    } catch (e) {
      console.warn('–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∑–≤—É–∫–∞:', e);
    }
    sourceNodeRef.current = null;
  }
};

/**
 * Gets the Russian name of a note
 */
const getNoteNameRu = (noteCode: string): string => {
  // Extract the note letter and octave (e.g., "C4" -> "C", "4")
  const noteLetter = noteCode.replace(/\d/g, '');
  const octave = noteCode.match(/\d+/)?.[0] || '';
  
  return `${NOTE_NAMES_RU[noteLetter]}${octave}`;
};

/**
 * Analyzes the current audio input to detect the pitch and note
 */
const analyzeAudio = async (): Promise<void> => {
  console.log('–ó–∞–ø—É—Å–∫ analyzeAudio, isListening=', isListening);
  
  if (!isListening) {
    console.log('–ü—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ, –≤—ã—Ö–æ–¥ –∏–∑ analyzeAudio');
    return;
  }
  
  if (!analyserNodeRef.current) {
    console.error('–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
    setError('–û—à–∏–±–∫–∞: –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
    return;
  }
  
  if (!audioContextRef.current) {
    console.error('–ê—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
    setError('–û—à–∏–±–∫–∞: –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
    return;
  }
  
  // Check audio context state
  if (audioContextRef.current.state !== 'running') {
    console.log(`–ê—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω, —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: ${audioContextRef.current.state}`);
    try {
      await audioContextRef.current.resume();
      console.log('–ê—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω');
    } catch (e) {
      console.error('–ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ–∑–æ–±–Ω–æ–≤–∏—Ç—å –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç:', e);
      setError(`–û—à–∏–±–∫–∞ –∞—É–¥–∏–æ: ${e instanceof Error ? e.message : '–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –∞—É–¥–∏–æ'}`);
      setIsListening(false);
      return;
    }
  }
  
  // Check if enough time has passed since last analysis
  const now = Date.now();
  if (now - lastAnalysisTimeRef.current < ANALYSIS_INTERVAL) {
    // Schedule next analysis
    rafIdRef.current = requestAnimationFrame(analyzeAudio);
    return;
  }
  lastAnalysisTimeRef.current = now;
  
  try {
    // Get time-domain data for volume calculation
    const timeDataArray = new Float32Array(analyserNodeRef.current.fftSize);
    analyserNodeRef.current.getFloatTimeDomainData(timeDataArray);
    
    // Calculate signal volume (RMS)
    const currentVolume = calculateRMS(timeDataArray);
    setVolume(currentVolume);
    
    // Only analyze pitch if volume is above threshold
    if (currentVolume > VOLUME_THRESHOLD) {
      console.log('–ì—Ä–æ–º–∫–æ—Å—Ç—å –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞:', currentVolume);
      
      // Copy time-domain data to buffer for analysis
      const buffer = audioBufferRef.current;
      if (!buffer) {
        console.error('–ê—É–¥–∏–æ –±—É—Ñ–µ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω');
        // –ü—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –±—É—Ñ–µ—Ä
        const bufferSize = audioContextRef.current.sampleRate * 0.5;
        audioBufferRef.current = audioContextRef.current.createBuffer(
          1, bufferSize, audioContextRef.current.sampleRate
        );
        
        // Schedule next frame and return from this one
        rafIdRef.current = requestAnimationFrame(analyzeAudio);
        return;
      }
      
      const channelData = buffer.getChannelData(0);
      channelData.set(timeDataArray.slice(0, Math.min(timeDataArray.length, channelData.length)));
      
      try {
        // Use YIN algorithm for pitch detection
        const pitchResults = await yinPitchTracking(audioContextRef.current, buffer);
        
        if (pitchResults.length > 0 && pitchResults[0].probability > 0.7) {
          const { frequency, probability } = pitchResults[0];
          console.log(`–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —á–∞—Å—Ç–æ—Ç–∞: ${frequency.toFixed(2)} –ì—Ü, –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: ${probability.toFixed(2)}`);
          
          // Use frequency to identify the note
          const noteInfo = identifyNote(frequency);
          
          // Check note stability (to reduce flickering)
          if (noteInfo.note === lastNoteRef.current) {
            noteStabilityCounterRef.current++;
          } else {
            noteStabilityCounterRef.current = 0;
            lastNoteRef.current = noteInfo.note;
          }
          
          // Only update display if note is stable
          if (noteStabilityCounterRef.current >= NOTE_STABILITY_THRESHOLD) {
            console.log(`–°—Ç–∞–±–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –Ω–æ—Ç–∞: ${noteInfo.note}, ${noteInfo.cents} —Ü–µ–Ω—Ç–æ–≤`);
            setDetectedNote({
              note: noteInfo.note,
              nameRu: getNoteNameRu(noteInfo.note),
              frequency,
              cents: noteInfo.cents,
            });
          }
        } else {
          console.log('–ß–∞—Å—Ç–æ—Ç–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∏–ª–∏ –Ω–∏–∑–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å');
        }
      } catch (pitchErr) {
        console.error('–û—à–∏–±–∫–∞ –≤ –∞–ª–≥–æ—Ä–∏—Ç–º–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—ã—Å–æ—Ç—ã —Ç–æ–Ω–∞:', pitchErr);
        // –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∞–Ω–∞–ª–∏–∑ –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –æ—à–∏–±–∫—É
      }
    } else {
      // Reset when volume is too low
      if (detectedNote) {
        console.log('–ì—Ä–æ–º–∫–æ—Å—Ç—å —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è, —Å–±—Ä–æ—Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –Ω–æ—Ç—ã');
        setDetectedNote(null);
      }
    }
  } catch (analysisErr) {
    console.error('–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∞–Ω–∞–ª–∏–∑–∞ –∞—É–¥–∏–æ:', analysisErr);
    // –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º —Ü–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏
  }
  
  // Schedule next analysis only if still listening
  if (isListening) {
    rafIdRef.current = requestAnimationFrame(analyzeAudio);
  } else {
    console.log('–ü—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∞–Ω–∞–ª–∏–∑–∞');
  }
};

/**
 * Gets the tuning status based on cents deviation
 */
const getTuningStatus = (): { status: 'perfect' | 'close' | 'out-of-tune', color: string } => {
  if (!detectedNote) return { status: 'out-of-tune', color: '#ccc' };
  
  const cents = Math.abs(detectedNote.cents);
  if (cents < 5) {
    return { status: 'perfect', color: '#4caf50' }; // Green
  } else if (cents < 15) {
    return { status: 'close', color: '#ff9800' }; // Orange
  } else {
    return { status: 'out-of-tune', color: '#f44336' }; // Red
  }
};

/**
 * Gets the arrow direction for tuning guidance
 */
const getTuningDirection = (): string => {
  if (!detectedNote) return '‚Äì';
  
  if (detectedNote.cents < -5) {
    return '‚Üì'; // Too flat, need to tune up
  } else if (detectedNote.cents > 5) {
    return '‚Üë'; // Too sharp, need to tune down
  } else {
    return '‚úì'; // In tune
  }
};

/**
 * Effect to cleanup audio resources when component unmounts
 */
useEffect(() => {
  // Start analysis when listening state changes
  if (isListening) {
    analyzeAudio();
  }
  
  // Cleanup function
  return () => {
    // Cancel any pending animation frame
    if (rafIdRef.current) {
      cancelAnimationFrame(rafIdRef.current);
    }
    
    // Stop microphone stream
    if (microphoneStreamRef.current) {
      microphoneStreamRef.current.getTracks().forEach(track => track.stop());
    }
    
    // Disconnect audio nodes
    if (sourceNodeRef.current) {
      sourceNodeRef.current.disconnect();
    }
    
    // Close audio context
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
    }
  };
}, [isListening]);

// Calculate tuning status
const tuningStatus = getTuningStatus();
const tuningDirection = getTuningDirection();

return (
  <div className="p-4 bg-gray-50 rounded-lg">
    <h1 className="text-2xl font-bold mb-6 text-center">–¢—é–Ω–µ—Ä –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏</h1>
    
    <div className="bg-white p-4 rounded-lg shadow mb-6">
      {error && (
        <div className="bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded mb-4">
          {error}
        </div>
      )}
      
      {hasMicrophonePermission === false && (
        <div className="bg-yellow-100 border border-yellow-400 text-yellow-700 px-4 py-3 rounded mb-4">
          <p className="font-bold">–î–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç</p>
          <p>–î–ª—è —Ä–∞–±–æ—Ç—ã —Ç—é–Ω–µ—Ä–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –±—Ä–∞—É–∑–µ—Ä–∞.</p>
          <div className="mt-2">
            <ol className="list-decimal pl-6 text-sm">
              <li>–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —É –≤–∞—Å –ø–æ–¥–∫–ª—é—á–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω</li>
              <li>–í –∞–¥—Ä–µ—Å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ –±—Ä–∞—É–∑–µ—Ä–∞ –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∏–∫–æ–Ω–∫—É üîí –∏–ª–∏ ‚ÑπÔ∏è</li>
              <li>–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –¥–ª—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ "–†–∞–∑—Ä–µ—à–∏—Ç—å"</li>
              <li>–û–±–Ω–æ–≤–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π</li>
            </ol>
          </div>
        </div>
      )}
      
      <div className="flex justify-center mb-6">
        <button 
          className={`py-2 px-6 rounded-full text-white font-medium focus:outline-none transition-colors ${
            isListening 
              ? 'bg-red-500 hover:bg-red-600' 
              : 'bg-[var(--primary)] hover:bg-[var(--primary-light)]'
          }`}
          onClick={isListening ? stopListening : startListening}
          disabled={hasMicrophonePermission === false}
        >
          {isListening ? '–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å' : '–ù–∞—á–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫—É'}
        </button>
      </div>
      
      {/* Status indicator */}
      <div className="text-center text-sm mb-4">
        <div className="flex items-center justify-center">
          <div className={`w-3 h-3 rounded-full mr-2 ${
            isListening ? 'bg-green-500 animate-pulse' : 'bg-gray-400'
          }`}></div>
          <span>
            –°—Ç–∞—Ç—É—Å: {isListening ? '–ü—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ' : '–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞'}
          </span>
        </div>
      </div>
      
      <div className="mb-4">
        <label className="block mb-2">–≠—Ç–∞–ª–æ–Ω–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ (A4):</label>
        <div className="flex items-center">
          <button
            className="bg-gray-200 px-3 py-1 rounded-l"
            onClick={() => setReferenceFrequency(prev => Math.max(430, prev - 1))}
          >
            -
          </button>
          <input 
            type="number" 
            min="430" 
            max="450"
            value={referenceFrequency}
            onChange={(e) => setReferenceFrequency(Number(e.target.value))}
            className="w-20 text-center border-t border-b border-gray-300 py-1"
          />
          <button
            className="bg-gray-200 px-3 py-1 rounded-r"
            onClick={() => setReferenceFrequency(prev => Math.min(450, prev + 1))}
          >
            +
          </button>
          <span className="ml-2">–ì—Ü</span>
        </div>
      </div>
      
      <div className="mb-4">
        <div className="w-full bg-gray-200 rounded-full h-2.5">
          <div 
            className="bg-blue-600 h-2.5 rounded-full transition-all duration-300"
            style={{ width: `${Math.min(100, volume * 100 * 5)}%` }}
          ></div>
        </div>
        <div className="text-center text-xs text-gray-500 mt-1">
          –£—Ä–æ–≤–µ–Ω—å –≥—Ä–æ–º–∫–æ—Å—Ç–∏
        </div>
      </div>
    </div>
    
    {/* Tuning Display */}
    <div className="bg-white p-6 rounded-lg shadow mb-6 text-center">
      {detectedNote ? (
        <>
          <div className="flex justify-between items-center mb-6">
            <div className="text-4xl font-bold text-gray-500">
              {detectedNote.note.replace(/\d/g, '')}
            </div>
            <div className="text-6xl font-bold" style={{ color: tuningStatus.color }}>
              {detectedNote.nameRu.replace(/\d/g, '')}
              <span className="text-3xl ml-1">{detectedNote.note.match(/\d+/)?.[0] || ''}</span>
            </div>
            <div className="text-4xl font-bold text-gray-500">
              {detectedNote.frequency.toFixed(1)} –ì—Ü
            </div>
          </div>
          
          {/* Tuning Meter */}
          <div className="relative h-24 mb-4">
            <div className="absolute top-0 left-0 w-full h-4 bg-gray-200 rounded-full overflow-hidden">
              {/* Center line */}
              <div className="absolute top-0 left-1/2 w-1 h-full bg-green-500 transform -translate-x-1/2"></div>
              
              {/* Tuning indicator */}
              <div 
                className="absolute top-0 h-full bg-blue-500 transition-all duration-300 w-4 rounded-full"
                style={{ 
                  left: `calc(50% + ${detectedNote.cents * 2}px)`,
                  transform: 'translateX(-50%)'
                }}
              ></div>
              
              {/* Scale markers */}
              <div className="absolute top-full mt-2 w-full flex justify-between px-4 text-xs text-gray-500">
                <span>-50</span>
                <span>-30</span>
                <span>-10</span>
                <span>0</span>
                <span>+10</span>
                <span>+30</span>
                <span>+50</span>
              </div>
            </div>
            
            <div className="mt-12 text-center">
              <div className="text-5xl font-bold" style={{ color: tuningStatus.color }}>
                {tuningDirection}
              </div>
              <div className="mt-2 text-xl">
                {detectedNote.cents > 0 ? '+' : ''}{detectedNote.cents.toFixed(0)} —Ü–µ–Ω—Ç–æ–≤
              </div>
            </div>
          </div>
          
          <div className="text-sm text-gray-600 mt-4">
            {detectedNote.cents < -5 ? (
              "–ù–∏–∂–µ –Ω—É–∂–Ω–æ–π –Ω–æ—Ç—ã (–ø–æ–¥—Ç—è–Ω–∏—Ç–µ —Å—Ç—Ä—É–Ω—É)"
            ) : detectedNote.cents > 5 ? (
              "–í—ã—à–µ –Ω—É–∂–Ω–æ–π –Ω–æ—Ç—ã (–æ—Å–ª–∞–±—å—Ç–µ —Å—Ç—Ä—É–Ω—É)"
            ) : (
              "–ù–æ—Ç–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ!"
            )}
          </div>
        </>
      ) : (
        <div className="py-12 text-gray-500">
          {isListening ? (
            <>
              <svg className="mx-auto w-16 h-16 animate-pulse" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>
              </svg>
              <p className="mt-4 text-xl">–ò–∑–≤–ª–µ–∫–∏—Ç–µ –∑–≤—É–∫ –Ω–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ...</p>
            </>
          ) : (
            <>
              <svg className="mx-auto w-16 h-16" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth="2" d="M15.536 8.464a5 5 0 010 7.072m2.828-9.9a9 9 0 010 12.728M5.586 15.536a5 5 0 01-.707-7.07m-2.122 9.9a9 9 0 010-12.728"></path>
              </svg>
              <p className="mt-4 text-xl">–ù–∞–∂–º–∏—Ç–µ "–ù–∞—á–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫—É" –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞</p>
            </>
          )}
        </div>
      )}
    </div>
    
    {/* Instructions */}
    <div className="bg-white p-4 rounded-lg shadow">
      <h2 className="text-xl font-semibold mb-4">–ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç—é–Ω–µ—Ä–æ–º</h2>
      
      <ol className="list-decimal pl-5 space-y-2">
        <li>–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É "–ù–∞—á–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫—É" –∏ —Ä–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É</li>
        <li>–ò–∑–≤–ª–µ–∫–∏—Ç–µ –∑–≤—É–∫ –Ω–∞ –≤–∞—à–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ (—Å—ã–≥—Ä–∞–π—Ç–µ –Ω–æ—Ç—É)</li>
        <li>–¢—é–Ω–µ—Ä –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –±–ª–∏–∂–∞–π—à—É—é –Ω–æ—Ç—É –∏ –ø–æ–∫–∞–∂–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ç–æ—á–Ω–æ –æ–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞</li>
        <li>–°–ª–µ–¥—É–π—Ç–µ —É–∫–∞–∑–∞–Ω–∏—è–º —Å—Ç—Ä–µ–ª–æ–∫ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏</li>
        <li>–ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏, –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ —ç—Ç–∞–ª–æ–Ω–Ω—É—é —á–∞—Å—Ç–æ—Ç—É A4 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 440 –ì—Ü)</li>
      </ol>
      
      <div className="mt-4 text-sm text-gray-600">
        <p><strong>–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:</strong> –î–ª—è –Ω–∞–∏–ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç—é–Ω–µ—Ä –≤ —Ç–∏—Ö–æ–º –ø–æ–º–µ—â–µ–Ω–∏–∏ –∏ –¥–µ—Ä–∂–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –±–ª–∏–∑–∫–æ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É.</p>
      </div>
    </div>
  </div>
);
};

export default MicrophoneTuner;